{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part I: Data Engineering"
   ],
   "metadata": {
    "id": "SsFtldtMYMGG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CXEwmOVfYG8b"
   },
   "outputs": [],
   "source": [
    "# Loading in standard packages for analysis, feel free to add an extra packages you'd like to use here\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# Loading in the corrupted dataset to be used in analysis and imputation\n",
    "houses_corrupted = pd.read_csv('https://raw.githubusercontent.com/PaoloMissier/CSC3831-2021-22/main/IMPUTATION/TARGET-DATASETS/CORRUPTED/HOUSES/houses_0.1_MAR.csv', header=0)\n",
    "# Remove an artifact from the dataset\n",
    "houses_corrupted.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above we've loaded in a corrupted version of a housing dataset. The anomalies need to be dealt with and missing values imputed."
   ],
   "metadata": {
    "id": "-UkViOchMMIg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Data Understanding [7]\n",
    "- Perform ad hoc EDA to understand and describe what you see in the raw dataset\n",
    "  - Include graphs, statistics, and written descriptions as appropriate\n",
    "  - Any extra information about the data you can provide here is useful, think about performing an analysis (ED**A**), what would you find interesting or useful?\n",
    "- Identify features with missing records, outlier records\n"
   ],
   "metadata": {
    "id": "abwbd_vBYsv7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Taking a First Look at the Data\n",
    "I am starting my exploratory data analysis by examining the first 10 rows of the `houses_corrupted` dataset using the `.head()` method. This gives me a quick overview of the data, allowing me to see the format, structure, and types of values in each column."
   ],
   "metadata": {
    "id": "lhWoDxiLK-fC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted.head(10)"
   ],
   "metadata": {
    "id": "G04uriMrZH7P",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "outputId": "d322bf12-b078-4f0a-f3d8-6d891480baec"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   median_house_value  median_income  housing_median_age  total_rooms  \\\n",
       "0            452600.0         8.3252                41.0        880.0   \n",
       "1            358500.0         8.3014                21.0       7099.0   \n",
       "2            352100.0         7.2574                52.0       1467.0   \n",
       "3            341300.0         5.6431                52.0       1274.0   \n",
       "4            342200.0         3.8462                52.0       1627.0   \n",
       "5            269700.0         4.0368                52.0        919.0   \n",
       "6            299200.0         3.6591                52.0       2535.0   \n",
       "7            241400.0         3.1200                52.0       3104.0   \n",
       "8            226700.0         2.0804                42.0       2555.0   \n",
       "9            261100.0         3.6912                52.0       3549.0   \n",
       "\n",
       "   total_bedrooms  population  households  latitude  longitude  \n",
       "0           129.0       322.0       126.0     37.88    -122.23  \n",
       "1          1106.0      2401.0      1138.0     37.86    -122.22  \n",
       "2           190.0         NaN       177.0     37.85    -122.24  \n",
       "3           235.0         NaN       219.0     37.85    -122.25  \n",
       "4           280.0       565.0       259.0     37.85    -122.25  \n",
       "5           213.0       413.0       193.0     37.85    -122.25  \n",
       "6           489.0      1094.0       514.0     37.84    -122.25  \n",
       "7           687.0      1157.0       647.0     37.84    -122.25  \n",
       "8           665.0      1206.0       595.0     37.84    -122.26  \n",
       "9           707.0      1551.0       714.0     37.84    -122.25  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a2909957-9c23-44be-9099-9ef75c7ada49\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>median_income</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452600.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358500.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352100.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341300.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342200.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>269700.0</td>\n",
       "      <td>4.0368</td>\n",
       "      <td>52.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>299200.0</td>\n",
       "      <td>3.6591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>241400.0</td>\n",
       "      <td>3.1200</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>226700.0</td>\n",
       "      <td>2.0804</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>261100.0</td>\n",
       "      <td>3.6912</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3549.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2909957-9c23-44be-9099-9ef75c7ada49')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a2909957-9c23-44be-9099-9ef75c7ada49 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a2909957-9c23-44be-9099-9ef75c7ada49');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2f348ebc-ca70-448f-b4bc-94ae8dd623e4\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f348ebc-ca70-448f-b4bc-94ae8dd623e4')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2f348ebc-ca70-448f-b4bc-94ae8dd623e4 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "houses_corrupted",
       "summary": "{\n  \"name\": \"houses_corrupted\",\n  \"rows\": 20640,\n  \"fields\": [\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115395.6158744132,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3842,\n        \"samples\": [\n          194300.0,\n          379000.0,\n          230100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9642961749327876,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 12120,\n        \"samples\": [\n          3.2359,\n          2.0644,\n          2.543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.584914333383178,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          35.0,\n          12.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2181.615251582787,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 5926,\n        \"samples\": [\n          699.0,\n          1544.0,\n          3966.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.2479059431317,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1928,\n        \"samples\": [\n          1045.0,\n          2728.0,\n          2118.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1170.5858104330641,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3884,\n        \"samples\": [\n          1080.0,\n          2361.0,\n          2849.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 382.3297528316099,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1815,\n        \"samples\": [\n          21.0,\n          750.0,\n          1447.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1359523974571117,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 862,\n        \"samples\": [\n          33.7,\n          34.41,\n          38.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.003531723502581,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 844,\n        \"samples\": [\n          -118.63,\n          -119.86,\n          -121.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From examining the first 10 rows of the dataset, it is evident that there are missing values, particularly in columns like `population` (for example, rows 2 and 3 show `NaN` values). I will now use the `info()` method to understand the data types of each column and obtain an initial count of non-null values, which will provide further insight into the extent of missing data."
   ],
   "metadata": {
    "id": "VKVjSCbtYmFp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nU-RnTrDAaW",
    "outputId": "4df9bd28-b1bc-44c5-d003-7918301df6d5"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   median_house_value  20640 non-null  float64\n",
      " 1   median_income       18576 non-null  float64\n",
      " 2   housing_median_age  18576 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          18576 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   latitude            20640 non-null  float64\n",
      " 8   longitude           20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the initial inspection using `info()`, I observed missing values in columns like `median_income`, `housing_median_age`, and `population`, as these columns show 18,576 non-null counts out of a total of 20,640 entries. To quantify these missing values more precisely, I will use `isnull()` and `sum()` to count the exact number of missing values in each column."
   ],
   "metadata": {
    "id": "HzjzO2bYb3kv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Missing values detection\n",
    "missing_data = houses_corrupted.isnull().sum()\n",
    "missing_percentage = (missing_data / houses_corrupted.shape[0]) * 100\n",
    "missing_info = pd.DataFrame({'Missing Values': missing_data, 'Percentage': missing_percentage})\n",
    "print(missing_info)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02-KuQoDwpnM",
    "outputId": "8f550b01-348a-4c11-f153-abf0ccf48086"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    Missing Values  Percentage\n",
      "median_house_value               0         0.0\n",
      "median_income                 2064        10.0\n",
      "housing_median_age            2064        10.0\n",
      "total_rooms                      0         0.0\n",
      "total_bedrooms                   0         0.0\n",
      "population                    2064        10.0\n",
      "households                       0         0.0\n",
      "latitude                         0         0.0\n",
      "longitude                        0         0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results, it is evident that `median_income`, `housing_median_age`, and `population` each have 2064 missing entries, which accounts for approximately 10% of the dataset."
   ],
   "metadata": {
    "id": "8GpSKsIA3WZw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Relationships, Distributions and Statistical Summaries\n",
    "\n",
    "Since the `houses_corrupted` dataset consists entirely of numerical values, I generated a pair plot using the `sns.pairplot` function to examine the center, spread, and skew of data. The pair plot enables us to visually explore the distributions and pairwise relationships between attributes, helping to identify trends, clusters, or unusual patterns that could impact the data analysis."
   ],
   "metadata": {
    "id": "EjFtfuN6jKRg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sns.pairplot(houses_corrupted)"
   ],
   "metadata": {
    "id": "tI2GM4ouL_4K"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to large volume of data points, it is challenging to determine the skew for each attribute directly from the pair plot alone. The dense overlapping points make it difficult to discern finer details in data distribution. To address this, I created a density plot for each attribute using the `sns.kdeplot` function, which provides a clearer view of the skewness of the data and distribution shape."
   ],
   "metadata": {
    "id": "EJ9DLsv_nhMr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['median_house_value'])"
   ],
   "metadata": {
    "id": "zB53gneRZer7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['median_income'])"
   ],
   "metadata": {
    "id": "gn1-ljuZaIZ5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['housing_median_age'])"
   ],
   "metadata": {
    "id": "o6hhHSxkaK6e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['total_rooms'])"
   ],
   "metadata": {
    "id": "ZT8hDvkzaLpS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['total_bedrooms'])"
   ],
   "metadata": {
    "id": "N_5dUwSPaMLe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['population'])"
   ],
   "metadata": {
    "id": "Stlpa71-aMot"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['households'])"
   ],
   "metadata": {
    "id": "6ZxTg2dZaecF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['latitude'])"
   ],
   "metadata": {
    "id": "qnMPnEz_ahSt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sns.kdeplot(houses_corrupted['longitude'])"
   ],
   "metadata": {
    "id": "Rlc6-KSraoQt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The density plots show that `median_house_value`, `median_income`, `total_rooms`, `total_bedrooms`, `population`, and `households` are all right-skewed with the majority of values clustered at lower ranges and a long tail extending to higher values. This right-skewness suggests a high concentration of data points at the lower end of each variable's range, with fewer outliers on the higher end.\n",
    "\n",
    "Furthermore, the density plot for `housing_median_age` shows multiple peaks, indicating a multimodal distribution rather than a simple skew. Unlike other variables, `housing_median_age` does not display a strong right or left skew but instead has several prominent peaks, showing varying concentrations of housing ages across different ranges.\n",
    "\n",
    "Additionally, the `latitude` and `longitude` plots display bimodal distributions, each with two distinct peaks. This indicates that there are two main clusters of data points in these attributes."
   ],
   "metadata": {
    "id": "UN7ifVrcoPsT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, I used the `describe` method to view the summary statistics of the numeric values."
   ],
   "metadata": {
    "id": "xpn4wzwQbJrU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted.describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "rCK7JP0NbRym",
    "outputId": "851ebf5b-99c9-4ec7-d3f4-82ce6ce5ba9e"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       median_house_value  median_income  housing_median_age   total_rooms  \\\n",
       "count        20640.000000   18576.000000        18576.000000  20640.000000   \n",
       "mean        206855.816909       3.929958           28.324182   2635.763081   \n",
       "std         115395.615874       1.964296           12.584914   2181.615252   \n",
       "min          14999.000000       0.499900            1.000000      2.000000   \n",
       "25%         119600.000000       2.560300           18.000000   1447.750000   \n",
       "50%         179700.000000       3.572400           28.000000   2127.000000   \n",
       "75%         264725.000000       4.870050           37.000000   3148.000000   \n",
       "max         500001.000000      15.000100           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households      latitude     longitude  \n",
       "count    20640.000000  18576.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean       537.898014   1488.069283    499.539680     35.631861   -119.569704  \n",
       "std        421.247906   1170.585810    382.329753      2.135952      2.003532  \n",
       "min          1.000000      3.000000      1.000000     32.540000   -124.350000  \n",
       "25%        295.000000    839.000000    280.000000     33.930000   -121.800000  \n",
       "50%        435.000000   1227.000000    409.000000     34.260000   -118.490000  \n",
       "75%        647.000000   1803.000000    605.000000     37.710000   -118.010000  \n",
       "max       6445.000000  35682.000000   6082.000000     41.950000   -114.310000  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-437d27c1-254b-4986-8ee2-06d5e52df680\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>median_income</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>18576.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>206855.816909</td>\n",
       "      <td>3.929958</td>\n",
       "      <td>28.324182</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1488.069283</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115395.615874</td>\n",
       "      <td>1.964296</td>\n",
       "      <td>12.584914</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1170.585810</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>119600.000000</td>\n",
       "      <td>2.560300</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179700.000000</td>\n",
       "      <td>3.572400</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1227.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>264725.000000</td>\n",
       "      <td>4.870050</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1803.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500001.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-437d27c1-254b-4986-8ee2-06d5e52df680')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-437d27c1-254b-4986-8ee2-06d5e52df680 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-437d27c1-254b-4986-8ee2-06d5e52df680');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-a50041f6-b55e-47cf-95d4-2a2c827d037f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a50041f6-b55e-47cf-95d4-2a2c827d037f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-a50041f6-b55e-47cf-95d4-2a2c827d037f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"houses_corrupted\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 156160.28379826449,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          206855.81690891474,\n          179700.0,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6565.972985292352,\n        \"min\": 0.4999,\n        \"max\": 18576.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.929958484065461,\n          3.5724,\n          18576.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6558.690730556797,\n        \"min\": 1.0,\n        \"max\": 18576.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          28.324181739879414,\n          28.0,\n          18576.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13944.990983306392,\n        \"min\": 2.0,\n        \"max\": 39320.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2635.7630813953488,\n          2127.0,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7176.364332780706,\n        \"min\": 1.0,\n        \"max\": 20640.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          537.8980135658915,\n          435.0,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12902.990881534364,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1488.0692829457364,\n          1227.0,\n          18576.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7167.532601135343,\n        \"min\": 1.0,\n        \"max\": 20640.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          499.5396802325581,\n          409.0,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7286.333552413666,\n        \"min\": 2.1359523974571117,\n        \"max\": 20640.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          35.63186143410853,\n          34.26,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7333.554670164394,\n        \"min\": -124.35,\n        \"max\": 20640.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -119.56970445736432,\n          -118.49,\n          20640.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first glance at the DataFrame output, we see that `median_house_value` has a maximum value of 500,001, while its mean is only 206,855. Since the mean is sensitive to outliers, this large gap between the mean and maximum suggests that the maximum value is likely an outlier. Similarly, the `median_income` has a maximum of 15.00 compared to a mean of 3.93, indicating potential outliers at the high end. For `total_rooms`, the maximum of 39,320 is significantly higher than the mean of 2,635, indicating to high outliers in this feature. The same pattern is observed with `total_bedrooms`, `population`, and `households`, where each maximum value greatly exceeds the mean, suggesting the presence of outliers in these variables.\n",
    "\n",
    "For `housing_median_age`, the maximum value is 52, while the mean is 28.32. The values are spread relatively even across its range, suggesting minimal outliers. `latitude` and `longitude` are within typical geographic boundaries, showing no extreme values. Together, these features exhibit distributions that appear consistent and without significant outliers."
   ],
   "metadata": {
    "id": "SmeIr5bIrEm3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the previous density plots, we observed that none of the attributes in the dataset follow a normal distribution. Therefore, the mean and standard deviation provided in this statistical summary may not be the most appropriate measures for these skewed distributions. A more suitable approach is to use the **median (50th percentile)** and the **median absolute deviation (MAD)**, as these are more reliable for skewed data. Since the MAD function is deprecated in Python, I will use the formula from Practical 1 to calculate it."
   ],
   "metadata": {
    "id": "sDcthxE8b_ov"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted.columns[:-1]\n",
    "\n",
    "houses_MAD = pd.DataFrame(columns=houses_corrupted.columns[:-1])\n",
    "mads = []\n",
    "\n",
    "# Calculate MAD\n",
    "for attribute in houses_corrupted.columns[:-1]:\n",
    "    mad = 1.483 * abs(houses_corrupted[attribute] - houses_corrupted[attribute].median()).median()\n",
    "    mads.append(mad)\n",
    "\n",
    "# Create a new DataFrame with the calculated MAD values\n",
    "houses_MAD.loc[0] = mads\n",
    "\n",
    "print(houses_MAD)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPB8pcihCiUt",
    "outputId": "4540df9f-f56d-4441-9211-04c9d606c15c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   median_house_value  median_income  housing_median_age  total_rooms  \\\n",
      "0            101437.2       1.660515              13.347     1181.951   \n",
      "\n",
      "   total_bedrooms  population  households  latitude  \n",
      "0         241.729     670.316     223.933   1.82409  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding Relationships Between Attributes\n",
    "\n",
    "Next, I aim to explore the relationships between attributes in the dataset to identify any significant correlations. By using `.corr()` method, I can calculate the correlation coefficients between pairs of numerical attributes, which will help me understand the strength and direction of these relationships. Since all attributes in the dataset are numerical, there is no need to remove any non-numerical columns for this analysis."
   ],
   "metadata": {
    "id": "kV0mTYWuLykE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted.corr()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "GasH-Jwim9fS",
    "outputId": "b01e6da3-c788-40b5-91f7-365d9bcae779"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    median_house_value  median_income  housing_median_age  \\\n",
       "median_house_value            1.000000       0.694887            0.097929   \n",
       "median_income                 0.694887       1.000000           -0.120147   \n",
       "housing_median_age            0.097929      -0.120147            1.000000   \n",
       "total_rooms                   0.134153       0.198818           -0.372323   \n",
       "total_bedrooms                0.050594      -0.009499           -0.329757   \n",
       "population                   -0.027855       0.006298           -0.305052   \n",
       "households                    0.065843       0.012754           -0.312948   \n",
       "latitude                     -0.144160      -0.096861            0.011372   \n",
       "longitude                    -0.045967      -0.008902           -0.106438   \n",
       "\n",
       "                    total_rooms  total_bedrooms  population  households  \\\n",
       "median_house_value     0.134153        0.050594   -0.027855    0.065843   \n",
       "median_income          0.198818       -0.009499    0.006298    0.012754   \n",
       "housing_median_age    -0.372323       -0.329757   -0.305052   -0.312948   \n",
       "total_rooms            1.000000        0.929893    0.857515    0.918484   \n",
       "total_bedrooms         0.929893        1.000000    0.877178    0.979829   \n",
       "population             0.857515        0.877178    1.000000    0.907096   \n",
       "households             0.918484        0.979829    0.907096    1.000000   \n",
       "latitude              -0.036100       -0.066318   -0.107525   -0.071035   \n",
       "longitude              0.044568        0.068378    0.099797    0.055310   \n",
       "\n",
       "                    latitude  longitude  \n",
       "median_house_value -0.144160  -0.045967  \n",
       "median_income      -0.096861  -0.008902  \n",
       "housing_median_age  0.011372  -0.106438  \n",
       "total_rooms        -0.036100   0.044568  \n",
       "total_bedrooms     -0.066318   0.068378  \n",
       "population         -0.107525   0.099797  \n",
       "households         -0.071035   0.055310  \n",
       "latitude            1.000000  -0.924664  \n",
       "longitude          -0.924664   1.000000  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-638fd05e-1c6d-4cfa-a7a2-6141777bec11\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>median_income</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>median_house_value</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.694887</td>\n",
       "      <td>0.097929</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.050594</td>\n",
       "      <td>-0.027855</td>\n",
       "      <td>0.065843</td>\n",
       "      <td>-0.144160</td>\n",
       "      <td>-0.045967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_income</th>\n",
       "      <td>0.694887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.120147</td>\n",
       "      <td>0.198818</td>\n",
       "      <td>-0.009499</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.096861</td>\n",
       "      <td>-0.008902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_median_age</th>\n",
       "      <td>0.097929</td>\n",
       "      <td>-0.120147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.372323</td>\n",
       "      <td>-0.329757</td>\n",
       "      <td>-0.305052</td>\n",
       "      <td>-0.312948</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>-0.106438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rooms</th>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.198818</td>\n",
       "      <td>-0.372323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929893</td>\n",
       "      <td>0.857515</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>0.044568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bedrooms</th>\n",
       "      <td>0.050594</td>\n",
       "      <td>-0.009499</td>\n",
       "      <td>-0.329757</td>\n",
       "      <td>0.929893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877178</td>\n",
       "      <td>0.979829</td>\n",
       "      <td>-0.066318</td>\n",
       "      <td>0.068378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>-0.027855</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.305052</td>\n",
       "      <td>0.857515</td>\n",
       "      <td>0.877178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907096</td>\n",
       "      <td>-0.107525</td>\n",
       "      <td>0.099797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>0.065843</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.312948</td>\n",
       "      <td>0.918484</td>\n",
       "      <td>0.979829</td>\n",
       "      <td>0.907096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>0.055310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>-0.144160</td>\n",
       "      <td>-0.096861</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>-0.066318</td>\n",
       "      <td>-0.107525</td>\n",
       "      <td>-0.071035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.924664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-0.045967</td>\n",
       "      <td>-0.008902</td>\n",
       "      <td>-0.106438</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.068378</td>\n",
       "      <td>0.099797</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>-0.924664</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-638fd05e-1c6d-4cfa-a7a2-6141777bec11')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-638fd05e-1c6d-4cfa-a7a2-6141777bec11 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-638fd05e-1c6d-4cfa-a7a2-6141777bec11');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8323dc7f-6c35-4ca1-bd2c-13aa50c4b014\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8323dc7f-6c35-4ca1-bd2c-13aa50c4b014')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8323dc7f-6c35-4ca1-bd2c-13aa50c4b014 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"houses_corrupted\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38255399316672484,\n        \"min\": -0.14416027687465752,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.14416027687465752,\n          0.6948874621191886,\n          -0.027855339420915958\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3927428099326603,\n        \"min\": -0.12014679533563892,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.09686117348804023,\n          1.0,\n          0.006298115842534689\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42611432202455396,\n        \"min\": -0.3723233270318012,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.011372118696642381,\n          -0.12014679533563892,\n          -0.3050522461987155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5175006175237357,\n        \"min\": -0.3723233270318012,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.03609959585612549,\n          0.19881821398695435,\n          0.8575154261579647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5423708405723632,\n        \"min\": -0.3297569650484243,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.06631840029001367,\n          -0.009499172888624438,\n          0.8771783142382904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5276741666802099,\n        \"min\": -0.3050522461987155,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.10752524396930992,\n          0.006298115842534689,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5399715103317569,\n        \"min\": -0.3129483883836272,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.07103543319190864,\n          0.012754199755049007,\n          0.9070960350013277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4856121981699645,\n        \"min\": -0.9246644339150366,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          -0.09686117348804023,\n          -0.10752524396930992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4853506728073779,\n        \"min\": -0.9246644339150366,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -0.9246644339150366,\n          -0.00890177971787561,\n          0.09979713292928905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the correlation coefficients, I can identify various types of correlations among the attributes in the dataset:\n",
    "\n",
    "1) Positive Strong Correlations:\n",
    "*   `total_rooms` vs `total_bedrooms`: Houses with more rooms tends to have more bedrooms.\n",
    "*   `population` vs `households`: Population increases as households increases. This relationship could aid data imputation, especially since `population` has missing values.\n",
    "*   `total_rooms` vs `households`: House with more rooms tends to have more households.\n",
    "*   `population` vs `total_rooms`: Higher population are usually found in houses with more total rooms.\n",
    "*   `median_income` vs `median_house_value`: Higher median income has a higher median house value. This can be useful when imputing missing `median_income` values.\n",
    "\n",
    "2) Weak Positive Correlation:\n",
    "*   `median_income` vs `total_rooms`: There is a slight positive correlation between income and the total number of rooms, but the relationship is weak.\n",
    "\n",
    "3) Negative Strong Correlation:\n",
    "*   `latitude` vs `longitude`: A strong negative correlation between these attributes suggests that as latitude increases, longitude decreases, showing an inverse relationship.\n",
    "\n",
    "4) Negative Weak Correlations:\n",
    "*   `latitude` vs `median_house_value`\n",
    "*   `latitude` vs `median_income`\n",
    "\n",
    "A weak negative correlation suggests that as one variable increases, the other decreases slightly, though they do not have a strong cause-effect relationship.\n",
    "\n",
    "\n",
    "It is also worth noting that `housing_median_age` shows weak correlations with most other attributes, indicating that the age of housing does not have a strong relationship with any attributes in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "lqE-gsCb0-YG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Outlier Identification [10]\n",
    "- Utilise a statistical outlier detection approach (i.e., **no** KNN, LOF, 1Class SVM)\n",
    "- Utilise an algorithmic outlier detection method of your choice\n",
    "- Compare results and decide what to do with identified outliers\n",
    "  - Include graphs, statistics, and written descriptions as appropriate\n",
    "- Explain what you are doing, and why your analysis is appropriate\n",
    "- Comment on benefits/detriments of statistical and algorithmic outlier detection approaches\n"
   ],
   "metadata": {
    "id": "CR74DAF_ZQUy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Statistical Outlier Detection Using the Interquartile Range (IQR) Method\n",
    "\n",
    "\n",
    "To detect outliers in this dataset, I used a statistical method called the **Interquartile Range (IQR)**, rather than the Z-score. Based on the density plots for each attribute from the previous section of the EDA, it is clear that the data does not follow a normal distribution, making Z-score less appropriate. The IQR method is more suitable for skewed data, as it focuses on the median and quartiles, rather than the mean and standard deviation, which are more sensitive to extreme values.\n",
    "\n",
    "The IQR method is simple to calculate and easy to interpret. In this approach, data points that fall below Q1 - 1.5 x IQR or above Q3 + 1.5 x IQR are considered outliers, where Q1 and Q3 represent the 25th and 75th percentiles of the data, respectively. This approach allows me to detect anomalies without letting them overly influence the analysis, making it a reliable choice for identifying outliers in skewed data."
   ],
   "metadata": {
    "id": "ZsBekFrEva5e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Outlier Detection using IQR\n",
    "outliers = pd.DataFrame()\n",
    "outlier_counts = {}\n",
    "\n",
    "for column in houses_corrupted.select_dtypes(include=[np.number]).columns:\n",
    "    Q1 = houses_corrupted[column].quantile(0.25)\n",
    "    Q3 = houses_corrupted[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Removing missing values before calculating outliers\n",
    "    column_data = houses_corrupted[column].dropna()\n",
    "    outliers[column] = column_data[(column_data < lower_bound) | (column_data > upper_bound)]\n",
    "\n",
    "    # Counting the outliers for ech column\n",
    "    outlier_counts[column] = outliers[column].notna().sum()\n",
    "\n",
    "print(\"Outliers Count per Column:\")\n",
    "for column, count in outlier_counts.items():\n",
    "    print(f\"{column}: {count} outliers\")\n"
   ],
   "metadata": {
    "id": "jPsaKYCZZPkv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4987c34f-ab37-4c46-cfbb-97fa7d9b3c80"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Outliers Count per Column:\n",
      "median_house_value: 0 outliers\n",
      "median_income: 0 outliers\n",
      "housing_median_age: 0 outliers\n",
      "total_rooms: 0 outliers\n",
      "total_bedrooms: 0 outliers\n",
      "population: 0 outliers\n",
      "households: 0 outliers\n",
      "latitude: 0 outliers\n",
      "longitude: 0 outliers\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "From the results, we can see that certain columns, such as `median_house_value`, `median_income`, `total_rooms`, `total_bedrooms`, `population`, and `households`, contain outliers. Other columns like `housing_median_age`, `latitude`, and `longitude`, show no outliers. This outcome aligns with my initial hypothesis from the statistical summary generated using the `.describe()` method, where I noted that attributes like `median_house_value` likely contain outliers due to the large gap between the mean and maximum values. Similarly, features like `housing_median_age` appear consistent and without extreme values, resulting in no outliers.\n",
    "\n",
    "It is important to note that I removed `NaN` values before calculating outliers (as shown in the code). This is done to ensure that missing values do not interfere with the calculations, which could result in inaccurate identification of outliers."
   ],
   "metadata": {
    "id": "Mn9M7UA_HsZi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithmic Outlier Detection Using Isolation Forest\n",
    "\n",
    "Another approach to detect outliers is to use an algorithmic method. I chose **Isolation Forest**, an anomaly detection algorithm that identifies outliers by isolating data points that are unusual or different from the rest. This approach is particularly suitable for this dataset because it does not assume any specific data distribution, making it flexible for handling various distributions, such as right-skewed or multimodal distributions, which are present in this dataset.\n",
    "\n",
    "The Isolation Forest algorithm identifies complex outliers by analysing multiple features together. Unlike the IQR method, it can detect anomalies that may not be extreme in any single dimension but are unusual in a multi-dimensional context. For example, a combination of `median_house_value` and `median_income` might reveal anomalies that would not be evident when examining these variables individually."
   ],
   "metadata": {
    "id": "mq0-gqADI64f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Removing rows that have missing values (essential in Isolation Forest)\n",
    "houses_cleaned = houses_corrupted.dropna()\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.1  , random_state=42)\n",
    "outliers_iforest = iso_forest.fit_predict(houses_cleaned.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Calculate anomaly scores\n",
    "anomaly_scores = iso_forest.decision_function(houses_cleaned.select_dtypes(include=[np.number]))\n",
    "\n",
    "houses_cleaned = houses_cleaned.copy()\n",
    "houses_cleaned['Outlier_IForest'] = outliers_iforest\n",
    "houses_cleaned['Anomaly_Score'] = anomaly_scores\n",
    "\n",
    "# Finding outliers\n",
    "outliers_count = np.sum(outliers_iforest == -1)\n",
    "print(f\"Isolation Forest detected {outliers_count} outliers\")\n",
    "\n",
    "houses_cleaned[['Outlier_IForest', 'Anomaly_Score']].head(10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "J8QiZ_owHsyH",
    "outputId": "3e4691ac-f20f-4c22-f1c4-82a10754e0d5"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Isolation Forest detected 1506 outliers\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Outlier_IForest  Anomaly_Score\n",
       "0                -1      -0.021837\n",
       "1                -1      -0.045286\n",
       "4                 1       0.064330\n",
       "5                 1       0.058378\n",
       "6                 1       0.076555\n",
       "7                 1       0.066471\n",
       "8                 1       0.094429\n",
       "9                 1       0.054799\n",
       "11                1       0.051613\n",
       "12                1       0.088933"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-84206955-df91-4788-bfb0-8352b0448973\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlier_IForest</th>\n",
       "      <th>Anomaly_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.021837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.045286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.058378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.076555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.094429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.051613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.088933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84206955-df91-4788-bfb0-8352b0448973')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-84206955-df91-4788-bfb0-8352b0448973 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-84206955-df91-4788-bfb0-8352b0448973');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1a693909-eadd-439f-ac3b-0ec75507aac5\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a693909-eadd-439f-ac3b-0ec75507aac5')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1a693909-eadd-439f-ac3b-0ec75507aac5 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"houses_cleaned[['Outlier_IForest', 'Anomaly_Score']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Outlier_IForest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Anomaly_Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.045939369315463975,\n        \"min\": -0.04528621990487558,\n        \"max\": 0.0944286022553657,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.05161264853702635,\n          -0.04528621990487558\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since Isolation Forest cannot handle missing values, I first removed rows with missing data using `.dropna()` to ensure a complete dataset. I set the contamination parameter to 0.1, expecting 10% of data points to be outliers. This choice aligns with prior observations from density plots and the IQR method. The density plots suggests that features like `median_house_values` and `median_income` showed right-skewed with potential extreme values. Similarly, the IQR method also identified outliers in several features, indicating that a notable but limited percentage of data points might be outliers. Setting contamination to 10% allows us to capture a moderate number of anomalies without being too strict about it.\n",
    "\n",
    "From the results, Isolation Forest identified 1506 outliers, with `Outlier_IForest` labeling inliers as 1 and outliers as -1. The `Anomaly_Score` provides a ranking of these outliers, where lower scores indicate stronger anomalies.\n",
    "\n",
    "In the displayed table, we see both inliers and outliers with their respective anomaly scores. For instance, row 1 has an anomaly score of -0.035, indicating a stronger outlier compared to other values. This score ranking can help us evaluate which outliers are severe enough for potential removal or require handling, such as capping extreme values, while minor anomalies may still contribute meaningful data to the analysis."
   ],
   "metadata": {
    "id": "mvfIyGQS7tsi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison of Statistical and Algorithmic Outlier Detection Results\n",
    "\n",
    "Comparing the results of the statistical outlier detection (IQR) and algorithmic detection (Isolation Forest) methods, we see that each approach identifies different sets of outliers.\n",
    "\n",
    "The IQR method identifies outliers based on individual feature distributions, flagging extreme values within each column independently. On the other hand, Isolation Forest is a multivariate approach that detected 1506 outliers across multiple features by considering patterns and interactions between columns. Additionally, it provides an anomaly score for each data point, allowing us to rank outliers by severity, where negative scores indicating a higher likelihood of being an outlier.\n",
    "\n",
    "To better understand the comparison, we can visualize the results for each method. This will highlight how the IQR method, which identifies outliers in a univariate context, differs from the multivariate approach of Isolation Forest."
   ],
   "metadata": {
    "id": "uIaW2vzKHbvH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Identifying Univariate Outliers with Box Plots (IQR Method)\n",
    "\n",
    "For the IQR method, we can use box plots to identify univariate outliers. In a box plot, values outside the whiskers are considered outliers."
   ],
   "metadata": {
    "id": "pY6PxisvKYlH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot box plot for IQR for columns that have outliers\n",
    "outlier_columns = ['median_house_value', 'median_income', 'total_rooms', 'total_bedrooms', 'population', 'households']\n",
    "for col in outlier_columns:\n",
    "    sns.boxplot(x=houses_corrupted[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "9oNviPJeMuvI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the box plots for all the columns with outliers, we can clearly see that the outliers, which are located outside the whiskers of each plot. All of these outliers are located beyond 1.5 times the interquartile range (IQR) above the upper quartile, indicating values that are significantly higher than the majority of data points in each attribute. This pattern suggests that these extreme values are unusual or anomalous, especially in distributions that are right-skewed, like `median_house_value` and `median_income`."
   ],
   "metadata": {
    "id": "NpDayrRWP_5n"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Identifying Multivariate Outliers with Isolation Forest Pair Plot\n",
    "\n",
    "For the Isolation Forest method, I used a pair plot to display each attribute plotted against all other attributes in the dataset. This approach allows us to observe multivariate relationships and see how each pair of feature interacts."
   ],
   "metadata": {
    "id": "TSjPzWw6QBFQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Dropping Anomaly Score (irrelevant)\n",
    "columns_to_plot = houses_cleaned.drop(columns=['Anomaly_Score'])\n",
    "\n",
    "# Visualize Isolation Forest outliers using a pair plot\n",
    "sns.pairplot(columns_to_plot, hue='Outlier_IForest', palette={1: 'blue', -1: 'red'})\n",
    "plt.suptitle(\"Isolation Forest Outliers in Pair Plot\", y=1.02)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "QrXtvy92MTht"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this plot, outliers detected by Isolation Forest are highlighted in red, while normal points (inliers) are shown in blue. The diagonal y=x line represents the same attribute plotted against itself, displaying the distribution of each individual feature, often as histograms or density plots along this line.\n",
    "\n",
    "We can observe that many red points (outliers) cluster in regions where data points diverge from typical patterns across multiple dimensions. This highlights the effectiveness of Isolation Forest in identifying anomalies that may go unnoticed in univariable analysis, providing a more comprehensive understanding of the dataset's structure and unusual data points."
   ],
   "metadata": {
    "id": "vrv_3GQCYoKj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling Outliers\n",
    "\n",
    " To determine the best way to handle the identified outliers, I will evaluate each detection method separately as they capture outliers based on different criteria. I will first address the outliers detected by the statistical IQR method. When handling these outliers, I considered two options, which are removing or capping them.\n",
    "\n",
    " While removing outliers might seem like a quick solution, doing so could significantly reduce the size of dataset, especially given the high number of outliers in `median_house_value` and `median_income`. Outliers in these columns may represent meaningful high or low values, providing insights into the data's range and diversity. Removing them risks losing valuable information about extreme cases. Instead, I opted for a more balanced approach by capping the outliers, setting limits on the minimum and maximum values. This method retains all data points while minimizing the impact of extreme values on the model or analysis."
   ],
   "metadata": {
    "id": "wtd_0tbcg1Jm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def cap_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound) # Capping values below the lower bound and above the upper bound\n",
    "\n",
    "iqr_outlier_columns = ['median_house_value', 'median_income', 'total_rooms', 'total_bedrooms', 'population', 'households']\n",
    "\n",
    "for column in iqr_outlier_columns:\n",
    "    cap_outliers_iqr(houses_corrupted, column)\n",
    "\n",
    "print(houses_corrupted[iqr_outlier_columns].describe())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt_t5ZVc8lrs",
    "outputId": "6a8c2864-8876-4acf-898d-943560fe1ba1"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       median_house_value  median_income   total_rooms  total_bedrooms  \\\n",
      "count        20640.000000   18576.000000  20640.000000    20640.000000   \n",
      "mean        205981.224976       3.863265   2441.692472      502.727859   \n",
      "std         113217.350152       1.732667   1397.790038      287.520059   \n",
      "min          14999.000000       0.499900      2.000000        1.000000   \n",
      "25%         119600.000000       2.560300   1447.750000      295.000000   \n",
      "50%         179700.000000       3.572400   2127.000000      435.000000   \n",
      "75%         264725.000000       4.870050   3148.000000      647.000000   \n",
      "max         482412.500000       8.334675   5698.375000     1175.000000   \n",
      "\n",
      "         population    households  \n",
      "count  18576.000000  20640.000000  \n",
      "mean    1396.965601    469.020107  \n",
      "std      796.295565    265.507540  \n",
      "min        3.000000      1.000000  \n",
      "25%      839.000000    280.000000  \n",
      "50%     1227.000000    409.000000  \n",
      "75%     1803.000000    605.000000  \n",
      "max     3249.000000   1092.500000  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the results after capping, we can see that the maximum values in each column have been adjusted compared to the original dataset. These capped values help prevent extreme outliers from distorting the distribution while preserving the overall data structure. If we run the IQR method again to identify outliers, we would find 0 outliers in the capped columns. This is because the capping process adjusted all values outside the acceptable IQR range (1.5 times the interquartile range above the third quartile and below the first quartile) to lie within the defined bounds, effectively eliminating extreme values that were previously identified as outliers."
   ],
   "metadata": {
    "id": "bmr2XCEAC1p8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To handle outliers detected by the Isolation Forest, I chose a balanced approach similar to the IQR method. However, instead of setting upper and lower bounds like with the IQR, I capped extreme values based on their anomaly scores. In this case, I set a threshold of -0.05 of the anomaly score. Data points with scores below -0.05 are considered extreme outliers. This threshold is based on observing the distribution of anomaly scores of the dataset."
   ],
   "metadata": {
    "id": "UKvSD9cJEfds"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "threshold = -0.05\n",
    "\n",
    "# Filtering the dataset to remove outliers with high anomaly scores\n",
    "houses_filtered = houses_cleaned[houses_cleaned['Anomaly_Score'] >= threshold]\n",
    "\n",
    "print(\"Filtered dataset size:\", houses_filtered.shape)\n",
    "print(\"Original dataset size:\", houses_cleaned.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ1gpvmsEgG9",
    "outputId": "3b8adedf-4314-4727-9ce4-bb465ea2c445"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filtered dataset size: (14903, 11)\n",
      "Original dataset size: (15059, 11)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results, the dataset is reduced from its original size, showing that extreme outliers have been effectively handled. This approach keeps the most informative data points while minimizing the skewing effect of severe outliers."
   ],
   "metadata": {
    "id": "85K2hQtaXQWh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benefits and Drawbacks of Statistical and Algorithmic Outlier Detection Methods\n",
    "\n",
    "**Statistical Detection Using the IQR Method**\n",
    "\n",
    "The **benefits** of using the IQR method for statistical outlier detection are that it is easy to compute, interpret, and implement, allowing for quick identification of potential outliers without complex calculations. Additionally, unlike methods based on mean and standard deviation, the IQR method is more robust to extreme values because it relies on quartiles, which are less sensitive to outliers.\n",
    "\n",
    "On the other hand, the **drawbacks** of the IQR method include its limitation to univariate analysis. It is most effective for detecting outliers in individual variables and lacks the ability to capture interactions between variables, which limits its usefulness in multivariate datasets. Additionally, it can sometimes be overly sensitive to extreme values, mistakenly classifying them as outliers."
   ],
   "metadata": {
    "id": "Y7Xqj2xHE8Np"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Algorithmic Outlier Detection Using Isolation Forest**\n",
    "\n",
    "The **benefits** of using Isolation Forest for algorithmic outlier detection is that its effectiveness in detecting multi-dimensional outliers. This is especially useful in datasets where outliers arise from unique feature combinations, such as the relationships we observed between `median_income` and `median_house_value` in our correlation analysis. Additionally, Isolation Forest provides an anomaly score for each data point, helping to prioritize outliers and make informed decisions on handling them.\n",
    "\n",
    "However, **drawbacks** of Isolation Forest include its dependency on the contamination parameter. Setting this incorrectly can lead to misidentification of outliers, so some prior knowledge or estimation is needed. Isolation Forest also uses random splits to partition data, which, while effective, can make it harder to understand exactly why a point is flagged as an outlier compared to simpler methods like the IQR method."
   ],
   "metadata": {
    "id": "H0zOdN4OkKQj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Imputation [10]\n",
    "- Identify which features should be imputed and which should be removed\n",
    "  - Provide a written rationale for this decision\n",
    "- Impute the missing records using KNN imputation\n",
    "- Impute the missing records using MICE imputation\n",
    "- Compare both imputed datasets feature distributions against each other and the non-imputed data\n",
    "- Build a regressor on all thre datasets\n",
    "  - Use regression models to predict house median price\n",
    "  - Compare regressors of non-imputed data against imputed datas\n",
    "  - **Note**: If you're struggling to compare against the original dataset focus on comparing the two imputed datasets against each other\n"
   ],
   "metadata": {
    "id": "MOZ1nqTXZswr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use this dataset for comparison against the imputed datasets\n",
    "houses = pd.read_csv('https://raw.githubusercontent.com/PaoloMissier/CSC3831-2021-22/main/IMPUTATION/TARGET-DATASETS/ORIGINAL/houses.csv', header=0)"
   ],
   "metadata": {
    "id": "JdfHAY07QCef"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "To determine whether to impute or remove the missing values, I will revisit the insights from the exploratory data analysis. The missing data is in the `median_income`, `housing_median_age`, and `population` columns, each with around 10% missing values. This missingness is likely not completely random or missing not at random (MNAR), as only specific attributes have missing data.\n",
    "\n",
    "In terms of correlations, some of these features show strong relationships with others. For example, `median_income` has a strong positive correlation with `median_house_value`, and `population` is strongly correlated with `total_rooms` and `households`. These correlations make imputation a more suitable option since we can leverage these related variables to predict missing values. However, the `housing_median_age` column, has weak correlations with most other features. While this might limit the accuracy of imputation for `housing_median_age`, the weak correlations do not necessarily pose a signficant issue, as we can still use methods like mean or median imputation for this feature.\n",
    "\n",
    "Given the moderate level of missingness (10%), and the opportunity to use related features for estimation, **imputation** is the preferred approach for handling missing data in these three columns. Imputing the missing values allows us to retain the entire dataset, avoiding the potential data loss that could result from removing rows with missing values."
   ],
   "metadata": {
    "id": "ys8cKpE7Tpmv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute Missing Records Using KNN Imputation\n",
    "\n",
    "To impute missing values in `median_income`, `housing_median_age`, and `population` using K-Nearest Neighbors (KNN) Imputation, we can utilize the `KNNImputer` class from `skikit-learn`. This approach specifies a \"K\" parameter, which determines the number of nearest neighbors used to estimate the missing value based on their mean."
   ],
   "metadata": {
    "id": "fQJA1Hc9Z9g5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Only selecting columns that has missing records\n",
    "missing_data_columns = houses_corrupted[['median_income', 'housing_median_age', 'population']]\n",
    "\n",
    "# Using the standard value for n_neighbors\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Make a copy of the original data\n",
    "houses_corrupted_knn_imputed = houses_corrupted.copy()\n",
    "imputed_values = knn_imputer.fit_transform(missing_data_columns)\n",
    "\n",
    "houses_corrupted_knn_imputed[['median_income', 'housing_median_age', 'population']] = imputed_values\n",
    "\n",
    "print(houses_corrupted_knn_imputed[['median_income', 'housing_median_age', 'population']].head(10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvlOBZOcovpO",
    "outputId": "a22cf968-496e-4f6c-96f0-3a9a1803015e"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   median_income  housing_median_age  population\n",
      "0         8.3252                41.0       322.0\n",
      "1         8.3014                21.0      2401.0\n",
      "2         7.2574                52.0      1425.6\n",
      "3         5.6431                52.0       680.4\n",
      "4         3.8462                52.0       565.0\n",
      "5         4.0368                52.0       413.0\n",
      "6         3.6591                52.0      1094.0\n",
      "7         3.1200                52.0      1157.0\n",
      "8         2.0804                42.0      1206.0\n",
      "9         3.6912                52.0      1551.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the results, we can observe that previously missing values in the `median_income`, `housing_median_age`, and `population` columns have been successfully filled using KNN Imputation. Each missing entry was replaced by the average of its 5 neighbors based on Euclidean distance. For example, in the `population` column, rows 2 and 3 now contain imputed values where they previously had `NaN`. To verify that all missing values have been successfully imputed, we can run the .info() command on the imputed dataset."
   ],
   "metadata": {
    "id": "2G7hBCGO_O_W"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted_knn_imputed.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKeW7Gd0IgNz",
    "outputId": "b318714c-6835-4af0-ecfb-04325f86002e"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   median_house_value  20640 non-null  float64\n",
      " 1   median_income       20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   latitude            20640 non-null  float64\n",
      " 8   longitude           20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results, we can see that all columns now display 20,640 non-null entries, confirming that all missing values have been successfully filled using KNN imputation."
   ],
   "metadata": {
    "id": "kUSJKmm5IjlY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute Missing Records Using MICE Imputation\n",
    "\n",
    "To impute missing values in `median_income`, `housing_median_age`, and `population` using Multiple Imputation by Chained Equations (MICE) Imputation, we can utilize the `IterativeImputer` class from `sklearn`. This approach uses multiple imputations to fill in missing data, then combines the results from these multiple imputations to create a final imputed dataset."
   ],
   "metadata": {
    "id": "wi_40TOeDEs7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Only selecting columns that has missing records\n",
    "missing_data_columns = houses_corrupted[['median_income', 'housing_median_age', 'population']]\n",
    "\n",
    "# Initialize the MICE Imputer\n",
    "mice_imputer = IterativeImputer(random_state=0)\n",
    "\n",
    "# Make a copy of the original data\n",
    "houses_corrupted_mice_imputed = houses_corrupted.copy()\n",
    "imputed_values = mice_imputer.fit_transform(missing_data_columns)\n",
    "\n",
    "houses_corrupted_mice_imputed[['median_income', 'housing_median_age', 'population']] = imputed_values\n",
    "\n",
    "print(houses_corrupted_mice_imputed[['median_income', 'housing_median_age', 'population']].head(10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9738qU8BDqUU",
    "outputId": "1b7d331b-9f90-4b8f-98a1-f81be135d47e"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   median_income  housing_median_age   population\n",
      "0         8.3252                41.0   322.000000\n",
      "1         8.3014                21.0  2401.000000\n",
      "2         7.2574                52.0   789.387626\n",
      "3         5.6431                52.0   828.086545\n",
      "4         3.8462                52.0   565.000000\n",
      "5         4.0368                52.0   413.000000\n",
      "6         3.6591                52.0  1094.000000\n",
      "7         3.1200                52.0  1157.000000\n",
      "8         2.0804                42.0  1206.000000\n",
      "9         3.6912                52.0  1551.000000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the results, we can see that the previously missing values in the `median_income`, `housing_median_age`, and `population` columns have been successfully filled using MICE Imputation. For instance, the `population` column in rows 2 and 3 now contains imputed values that reflect MICE's iterative process, where each variable is modeled based on the others. To verify that all missing values have been successfully imputed, we can run the .info() command on the imputed dataset."
   ],
   "metadata": {
    "id": "xF4FneQVaDvw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "houses_corrupted_mice_imputed.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WW7hkkMYRZt9",
    "outputId": "bc373f57-f7b3-4f5a-cb5f-b990540af3ee"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   median_house_value  20640 non-null  float64\n",
      " 1   median_income       20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   latitude            20640 non-null  float64\n",
      " 8   longitude           20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results, we can see that all columns now display 20,640 non-null entries, confirming that all missing values have been successfully filled using MICE imputation."
   ],
   "metadata": {
    "id": "5uB8wx9kaFRG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing Feature Distributions of KNN Imputation, MICE Imputation, and Non-Imputed Data\n",
    "\n",
    "To compare the feature distributions between the KNN-imputed, MICE-imputed, and non-imputed datasets, we use the `.describe()` method to generate summary statistics. This provides us with key insights like mean, median, standard deviation, and range for each feature. Comparing these statistics across datasets helps us spot any differences in central tendency and spread introduced by the imputation methods."
   ],
   "metadata": {
    "id": "7P9FmnEODnqY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Finding the summary statistics for columns with missing values\n",
    "knn_imputed_summary = houses_corrupted_knn_imputed[['median_income', 'housing_median_age', 'population']].describe()\n",
    "mice_imputed_summary = houses_corrupted_mice_imputed[['median_income', 'housing_median_age', 'population']].describe()\n",
    "original_summary = houses[['median_income', 'housing_median_age', 'population']].describe()\n",
    "\n",
    "print(\"KNN Imputed Data Summary Statistics:\")\n",
    "print(knn_imputed_summary)\n",
    "print(\"\\nMICE Imputed Data Summary Statistics:\")\n",
    "print(mice_imputed_summary)\n",
    "print(\"\\nOriginal Data Summary Statistics:\")\n",
    "print(original_summary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNPUmHQ4Msr3",
    "outputId": "35b4a383-9c62-4aa0-9d3e-359f61fe1807"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN Imputed Data Summary Statistics:\n",
      "       median_income  housing_median_age    population\n",
      "count   20640.000000         20640.00000  20640.000000\n",
      "mean        3.834808            28.74404   1401.663010\n",
      "std         1.664965            12.12569    767.286019\n",
      "min         0.499900             1.00000      3.000000\n",
      "25%         2.614675            19.00000    870.450000\n",
      "50%         3.568200            29.00000   1259.000000\n",
      "75%         4.739375            37.00000   1784.000000\n",
      "max         8.334675            52.00000   3249.000000\n",
      "\n",
      "MICE Imputed Data Summary Statistics:\n",
      "       median_income  housing_median_age    population\n",
      "count   20640.000000        20640.000000  20640.000000\n",
      "mean        3.864013           28.535284   1387.990253\n",
      "std         1.646045           11.970797    759.766327\n",
      "min         0.499900            1.000000      3.000000\n",
      "25%         2.661800           19.000000    876.000000\n",
      "50%         3.680730           29.244698   1245.000000\n",
      "75%         4.679625           36.000000   1726.000000\n",
      "max         8.334675           52.000000   3249.000000\n",
      "\n",
      "Original Data Summary Statistics:\n",
      "       median_income  housing_median_age    population\n",
      "count   20640.000000        20640.000000  20640.000000\n",
      "mean        3.870671           28.639486   1425.476744\n",
      "std         1.899822           12.585558   1132.462122\n",
      "min         0.499900            1.000000      3.000000\n",
      "25%         2.563400           18.000000    787.000000\n",
      "50%         3.534800           29.000000   1166.000000\n",
      "75%         4.743250           37.000000   1725.000000\n",
      "max        15.000100           52.000000  35682.000000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the key information across these three datasets, we can observe that each dataset presents different results, with the original data acting as the baseline, reflecting the true dataset's central tendency and spread.\n",
    "\n",
    "When comparing the means, we see that the mean of `median_income` is slightly lower in the KNN-imputed dataset than in MICE imputed one. However, for `housing_median_age` and `population`, the KNN-imputed dataset shows a slightly higher mean compared to MICE. In terms of standard deviation, In terms of standard deviation, KNN imputation has a slightly higher standard deviation across all three imputed columns compared to MICE.\n",
    "\n",
    "Overall, most statistics are close across the KNN, MICE, and original datasets, with no significant deviations, except for a noticeable difference in the population column’s mean. The original dataset has a population mean of approximately 1425, while the KNN and MICE imputed datasets have slightly higher means of 1489 and 1475, respectively. This indicates that both imputation methods increased the average population value, with KNN showing a slightly larger increase.\n",
    "\n",
    "Both methods produce distributions relatively close to the original dataset, making them viable options. To further examine this, we can visualize the distributions of `median_income`, `housing_median_age`, and `population` across the KNN, MICE, and original datasets using density plots.\n",
    "\n"
   ],
   "metadata": {
    "id": "yZxLBd0wS4KN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Density plot for median_income\n",
    "\n",
    "sns.kdeplot(houses_corrupted_knn_imputed['median_income'], label='KNN Imputed')\n",
    "sns.kdeplot(houses_corrupted_mice_imputed['median_income'], label='MICE Imputed')\n",
    "sns.kdeplot(houses['median_income'], label='Original')\n",
    "plt.legend()\n",
    "plt.title(\"Density Plot for median_income\")"
   ],
   "metadata": {
    "id": "4pnoGIiTb_xl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Density plot for housing_median_age\n",
    "\n",
    "sns.kdeplot(houses_corrupted_knn_imputed['housing_median_age'], label='KNN Imputed')\n",
    "sns.kdeplot(houses_corrupted_mice_imputed['housing_median_age'], label='MICE Imputed')\n",
    "sns.kdeplot(houses['housing_median_age'], label='Original')\n",
    "plt.legend()\n",
    "plt.title(\"Density Plot for housing_median_age\")"
   ],
   "metadata": {
    "id": "qgZL7io1cXMb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Density plot for population\n",
    "\n",
    "sns.kdeplot(houses_corrupted_knn_imputed['population'], label='KNN Imputed')\n",
    "sns.kdeplot(houses_corrupted_mice_imputed['population'], label='MICE Imputed')\n",
    "sns.kdeplot(houses['population'], label='Original')\n",
    "plt.legend()\n",
    "plt.title(\"Density Plot for population\")"
   ],
   "metadata": {
    "id": "o08GMoplS5qh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the Impact of Imputation Methods with Non-Imputed Data\n",
    "\n",
    "To look into the effect of imputation on model performance, I will build a regressor on each of the three datasets (KNN-imputed, MICE-imputed, and original) to predict `median_house_value`. While this target variable had no missing values, the imputation methods were applied to related features that may influence the model. Slight differences in feature values after imputation could impact the model's predictions and error metrics."
   ],
   "metadata": {
    "id": "w7VPv4W2Egcs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "# Loading data\n",
    "original_df = houses\n",
    "knn_imputed_df = houses_corrupted_knn_imputed\n",
    "mice_imputed_df = houses_corrupted_mice_imputed\n",
    "\n",
    "# Function to train and evaluate model\n",
    "def train_and_evaluate(df, dataset_name):\n",
    "    X = df.drop(columns=['median_house_value']) # Dropping median_house_value column\n",
    "    y = df['median_house_value']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Dataset Performance:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"R-squared Score (R2): {r2}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "train_and_evaluate(knn_imputed_df, \"KNN Imputed\")\n",
    "train_and_evaluate(mice_imputed_df, \"MICE Imputed\")\n",
    "train_and_evaluate(original_df, \"Original\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UE5ZVanWBerf",
    "outputId": "eb1edd81-d57d-4030-c1eb-9a87a97348e8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN Imputed Dataset Performance:\n",
      "Mean Absolute Error (MAE): 52445.71806368396\n",
      "Root Mean Squared Error (RMSE): 71655.34495983212\n",
      "R-squared Score (R2): 0.6062372669332499\n",
      "\n",
      "\n",
      "MICE Imputed Dataset Performance:\n",
      "Mean Absolute Error (MAE): 52097.87423496796\n",
      "Root Mean Squared Error (RMSE): 71170.6512518401\n",
      "R-squared Score (R2): 0.6115462589527283\n",
      "\n",
      "\n",
      "Original Dataset Performance:\n",
      "Mean Absolute Error (MAE): 50863.49784071707\n",
      "Root Mean Squared Error (RMSE): 69669.08763539213\n",
      "R-squared Score (R2): 0.6277645980446465\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the code, we drop the `median_house_value` column from `X` so that model learns only from other relevant features like `median_income`, `housing_median_age`, `population`, and more, which may influence house prices. The target variable `y` is set to `median_house_value`, which the model aims to predict. A simple Linear Regression model is trained on `X_train` and `y_train` and then used to make predictions.\n",
    "\n",
    "The results show that the KNN-imputed dataset has a Mean Absolute Error (MAE) of around 52445, a Root Mean Squared Error (RMSE) of 71655, and an R-squared (R^2) score of 0.61. The MICE-imputed dataset performs slightly better, with an MAE of about 52097, an RMSE of approximately 71170, and an R^2 score of 0.61. This suggests that MICE imputation may have preserved feature relationships slightly better than KNN, resulting in slightly lower errors. The original dataset provides the best performance, with an MAE of 50863, an RMSE of 69,669, and an R^2 of 0.63. These results indicate that the model performs best on the original data, likely because it captures the most accurate feature relationships without imputation.\n",
    "\n",
    "In summary, both imputed datasets perform similarly but slightly worst than the original data, which MICE being closer in accuracy to the original.\n",
    "\n"
   ],
   "metadata": {
    "id": "90ZLtwdUR23j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Conclusions & Throughts [3]\n",
    "- Discuss methods used for anomaly detection, pros/cons of each method\n",
    "- Discuss challenges/difficulties in anomaly detection implementation\n",
    "- Discuss methods used for imputation, pros/cons of each method\n",
    "- Discuss challenges/difficulties in imputation implementation"
   ],
   "metadata": {
    "id": "NtLeRqcsQRpB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion & Thoughts\n",
    "\n",
    "**Anomaly Detection**\n",
    "\n",
    "In this analysis, I used two primary methods for anomaly detection which are the Interquartile Range (IQR) method and the Isolation Forest algorithm. Reflecting on both techniques, each presented distinct pros and cons that influenced their effectiveness depending on the nature of the data.\n",
    "\n",
    "**Interquartile Range (IQR) Method**\n",
    "\n",
    "The IQR method is a statistical approach based on quartiles that defines outliers as values falling beyond 1.5 times the IQR from the first (Q1) or third (Q3) quartile.\n",
    "\n",
    "**Pros**\n",
    "- Simple and Easy to Implement:\n",
    "  - The IQR method is straightforward to compute, interpret, and apply, making it accessible for quickly identifying potential outliers without complex calculations.\n",
    "- Focuses on Quartiles:\n",
    "  - Since IQR focuses on the spread within the quartiles, it is unaffected by high extreme values in the dataset, which would otherwise skew the mean and standard deviation.\n",
    "- User-Friendly:\n",
    "  - Its simplicity makes it easy to understand, even for those with limited statistical knowledge.\n",
    "\n",
    "**Cons**\n",
    "- Limited to Univariate Analysis:\n",
    "  - The IQR method is primarily suited for identifying outliers within individual variables and does not account for interactions between multiple features, making it less effective for multivariate datasets.\n",
    "- May Remove Valid Data Points:\n",
    "  - In datasets with skewed distributions or heavy tails, like the houses_corrupted dataset, the IQR method might classify legitimate values as outliers, potentially leading to the loss of meaningful data.\n",
    "\n",
    "**Isolation Forest**\n",
    "\n",
    "The Isolation Forest is based on a decision tree algorithm which isolates data points by randomly partitioning the features. Outliers are effectively \"isolated\" through fewer splits compared to inliers which helps in identifying anomalies efficiently.\n",
    "\n",
    "**Pros**\n",
    "- Speed and Efficiency:\n",
    "  - Isolation Forest is computationally fast and efficient, allowing us to quickly analyze the dataset, detect outliers, and obtain anomaly scores.\n",
    "\n",
    "- Provides Anomaly Scores:\n",
    "  - The algorithm provided anomaly scores for each entry, allowing us to rank outliers by severity. For example, outliers with higher anomaly scores were considered more severe, guiding our decisions on whether to remove or cap these data points.\n",
    "\n",
    "**Cons**\n",
    "- Dependency on Contamination Parameter:\n",
    "  - In this dataset, the contamination parameter plays a significant role. Adjusting the contamination parameter results in a different number of detected outliers, which can impact the consistency of our analysis.\n",
    "- Unsupervised Nature:\n",
    "  - Isolation Forest operates in an unsupervised manner, meaning it lacks prior knowledge of what constitutes an anomaly in this housing dataset. This increases the risk of incorrectly labeling legitimate data points, such as high values in `median_income` or `housing_median_age`, as outliers.\n",
    "\n",
    "**Challenges in Anomaly Detection Implementation**\n",
    "\n",
    "When implementing anomaly detection, the IQR method was straightforward and easy to apply, with no issues in execution. However, I encountered several challenges when using the Isolation Forest method. Setting the contamination parameter, which controls the expected proportion of outliers, proved to be challenging. For this dataset, I initially set the contamination parameter to 0.1, resulting in 1506 outliers, but I also experimented with values like 0.2 and 0.3. These larger values identify a larger number of outliers. Without a clear knowledge for the expected number of outliers, selecting the right contamination value was difficult. This is because setting it too high or low would risk misidentifying normal points as outliers.\n",
    "\n",
    "Another challenge I faced with Isolation Forest was the interpretability of the results. Understanding why certain points were flagged as outliers was not always clear, as the algorithm provides limited information into its decision-making process. This lack of transparency in the anomaly scores made it necessary to consider additional validation steps to ensure accurate handling of flagged points."
   ],
   "metadata": {
    "id": "7lrraskvQnKu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Imputation**\n",
    "\n",
    "In this analysis, I used two main methods for imputation, which are Nearest Neighbors (KNN) imputation and Multiple Imputation by Chained Equations (MICE). Reflecting on both methods, each presented their own unique pros and cons.\n",
    "\n",
    "\n",
    "**K-Nearest Neighbors (KNN) Imputation**\n",
    "\n",
    "KNN imputation fills missing values by considering the values of the nearest neighbors based on feature similarity.\n",
    "\n",
    "**Pros**\n",
    "- Simplicity and Intuitiveness:\n",
    "  - KNN is based on the assumption that similar data points are likely to share similar values in missing fields, making it an intuitive choice. This approach worked well in the `houses_corrupted` dataset, where features like `median_income` and `population` often reflect neighborhood-based similarities.\n",
    "- Ease of Implementation:\n",
    "  - KNN has a straightforward setup, allowing it to be applied quickly for basic imputation needs without requiring complex configurations. Additionally, there are many online tutorials available that demonstrate how to implement this method, making it accessible for a wide range of users.\n",
    "\n",
    "**Cons**\n",
    "- Dependency on Tuning Parameter (`n_neighbors`):\n",
    "  - The accuracy of KNN imputation depends on the number of neighbors chosen, or the \"K\" parameter. Imputed values vary based on this choice, which requires testing and fine-tuning to determine the optimal setting.\n",
    "\n",
    "**Multiple Imputation by Chained Equations (MICE) Imputation**\n",
    "\n",
    "MICE imputes missing values through iterative modeling, treating each variable as a target in a regression model based on other features.\n",
    "\n",
    "**Pros**\n",
    "- Better Preservation of Feature Relationships:\n",
    "  - MICE provided a slight performance edge over KNN, indicating it may have better preserved the relationships between features. This was evident when comparing the model’s performance on the MICE-imputed data with the original data, as MICE showed slightly improved accuracy.\n",
    "- Reduces Bias:\n",
    "  - By iteratively modeling and filling missing values, MICE tends to reduce bias, providing more accurate imputations compared to simpler methods (e.g., mean or median imputation).\n",
    "- Faster Processing Time than KNN:\n",
    "  - In this dataset, MICE demonstrated faster processing than KNN, likely due to its iterative modeling approach, which avoids extensive pairwise distance calculations.\n",
    "\n",
    "**Cons**\n",
    "- Limited Interpretability:\n",
    "  - MICE can lack transparency since it iteratively imputes based on regression models across features. Unlike KNN, which simply fills based on neighboring values, MICE’s complex imputation process may make it harder to trace how each missing value was imputed.\n",
    "\n",
    "**Challenges in Imputation Implementation**\n",
    "\n",
    "One challenge I faced when implementing both imputation methods was fully understanding how each approach works. Despite researching KNN and MICE, I still found some aspects of their processes confusing, which impacted my confidence in applying them correctly.\n",
    "\n",
    "Another challenge was determining the `n_neighbors` value for KNN. I researched the parameter to understand its impact on imputation accuracy and decided to use the standard `n_neighbors = 5`. However, I also experimented with other values, each yielding different results. Choosing the optimal n_neighbors value was essential since too few or too many neighbors could reduce the accuracy of the imputed values, highlighting the importance of careful tuning in this method."
   ],
   "metadata": {
    "id": "4_TC9lEyGixZ"
   }
  }
 ]
}
